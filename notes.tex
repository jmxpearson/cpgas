\documentclass[11pt]{article}
\usepackage{amssymb,amsmath}

\begin{document}
\title{Changepoint gas}
\author{John Pearson}
\maketitle

\section{Problem}
We would like to perform rapid inference for discrete latent variables in long time series. For Hidden Markov Models, forward-backward inference is $\mathcal{O}(TM^2)$ with $M$ the number of latent states and $T$ the time. However, for hidden semi-Markov models, the run time is $\mathcal{O}(TM^2 D)$ with $D$ the maximum duration of a state.

However, in many cases where semi-Markov models would naturally be applied, transitions are sparse, and posteriors for the state variables approximately alternate between periods of high posterior certainty punctuated by uncertain transition regions of disparate length scales.

\section{Posterior Approximation}
For the case of variational inference over binary latent variables $z(t)$, we will switch from a representation in terms of states to a representation in terms of changepoints $c_k$. That is, for a given index $k$ representing a transition $0 \rightarrow 1$, we will have $z(t < c_k) = 0$ and $z(t \ge c_k) = 1$. Thus, $z(t)$ and $c_k$ are equivalent descriptions of the model, linked deterministically, and $\mathcal{H}[q(z)] = \mathcal{H}[q(c)]$, where $\mathcal{H}$ is the entropy of the distribution.

As a first approximation, then, we will use a mean field approximation for the changepoint locations
\begin{equation}
\label{qc}
    q(c) = \prod_{k = 1}^K \mathcal{N}(\mu_k, \sigma^2_k)
\end{equation}
for which we can easily calculate
\begin{equation}
    \mathcal{H}[q(c)] = \frac{K}{2}(\log 2\pi + 1) + \sum_k \log \sigma_k
\end{equation}
Clearly, entropy scales with the number of changepoints and the uncertainty of the changepoint locations. Note also that we have assumed a fixed number of changepoints, $K$, which, like $\mu$ and $\sigma$ should be thought of as a variational parameter to be optimized.\footnote{Of course, with variational inference, which maximizes the sum of the expected log evidence and the entropy, both terms should benefit from $K$ larger. Thus, constraining $K$ will rely on the prior over changepoints, which should also appropriately scale with $K$.}

\section{Example: Poisson firing}
Here, we consider the example of a Poisson process driven by such a binary latent state. That is, we observe in successive time bins of size $\Delta t$ event counts $N_t$ with instantaneous rate
\begin{equation}
    r(t) = \lambda \nu^{z(t)}
\end{equation}
Thus, if we write $t = k\Delta t$, we have
\begin{equation}
    N_k \sim \text{Pois}\left(\lambda \int_{(k - 1)\Delta t}^{k\Delta t} \nu^{z(t)} dt\right)
\end{equation}
Now, we would like to calculate the expectation of the log of this evidence under the variational posterior, for which we need
\begin{align}
    \mathbb{E}_q[\log p(N, z)] &= \mathbb{E}_q[\log p(N|z)] + \mathbb{E}_q[\log p(z)] \\
    &= \sum_k \left(N_k \mathbb{E}_q \left[ \log \int_{(k - 1)\Delta t}^{k\Delta t} \lambda \nu^{z(t)} dt \right] \right. \\
    &- \left.\lambda \mathbb{E}_q\left[ \int_{(k - 1)\Delta t}^{k\Delta t} \nu^{z(t)} dt\right]\right)
    + \mathbb{E}_q[\log p(z)]
\end{align}
Now assume for the moment we have the marginal distribution at each time: $\zeta(t) = \mathbb{E}_q[z(t)]$. Then
\begin{align}
    \sum_k \mathbb{E}_q\left[ \int_{(k - 1)\Delta t}^{k\Delta t} \nu^{z(t)} dt\right] &= \int \mathbb{E}_q \left[\nu^{z(t)}\right] dt = (1 - Z) + Z\nu
\end{align}
where
\begin{equation}
    Z \equiv \int \zeta(t) dt
\end{equation}
The expectation of the log integral is easy to compute if the change point is on either side of the interval in question. If we let $t_k \equiv k \Delta t$, then if the nearest changepoint $c_k \notin [t_{k -1}, t_k)$ the value of the integral is
\begin{equation}
    \int_{t_{k - 1}}^{t_k} \nu^{z(t)} = \nu^{z_k}(\Delta t)
\end{equation}
where $z_k$ is the value of the state in that bin. Thus
\begin{align}
    \sum_k M_k \mathbb{E}_q \left[
    \log \int_{t_{k - 1}}^{t_k} \nu^{z(t)}
    \right]
    &\approx \sum_k M_k \mathbb{E}_q \left[z_k \log \nu \right] \Delta t = \left[\int \rho(t) \zeta(t) dt \right] \log \nu
\end{align}
That is, we are averaging the expected value of $z$, $\zeta$, against the instantaneous event rate of the process
\begin{equation}
    \rho(t) = \sum_i \delta(t - t_i)
\end{equation}
with $i$ indexing events. Note that the approximation above is exact when the changepoints are located at the bin boundaries, since $z(t)$ is then constant within each bin.\footnote{I suspect, however, that the last expression is exact even without this assumption.} However, this requires us to use a discrete approximation to $p(c)$. We will return to this below.

With these results in hand, we can then calculate the variational objective
\begin{align}
    \mathcal{L} &= \mathbb{E}_q [\log p(M, z)] + \mathcal{H}[q(z)] \\
    &= M \log \lambda + \overline{M} \log \nu - \lambda [(T - Z) + Z\nu] + \mathbb{E}_q[\log p(c)] \\
    &+ \frac{K}{2}\log(2\pi e) + \sum_k \log \sigma_k
\end{align}
where we have defined
\begin{align}
    M &\equiv \int \rho(t) dt &
    \overline{M} &\equiv \int \rho(t) \zeta(t) dt
\end{align}
and replaced the prior on $z$ with the prior on $c$, since the two are equivalent. Finally, we need to use the ansatz (\ref{qc}) to calculate
\begin{equation}
    \zeta(t) = \mathbb{E}_q[z(t)] = \sum_k Q_k \Phi\left(\frac{t - \mu_k}{\sigma_k} \right)
\end{equation}
For the binary case, we have, without loss of generality, $Q_k = (-1)^k$, and we further assume that the changepoints are sparse enough that only the closest pair of changepoints to a given time contribute meaningfully to the sum. We can then easily calculate
\begin{align}
    \frac{\partial \zeta}{\partial \mu_k} &= -\frac{Q_k}{\sigma_k}\phi\left( \frac{t - \mu_k}{\sigma_k}\right) \\
    \frac{\partial \zeta}{\partial \sigma_k} &= -\frac{t - \mu_k}{\sigma_k^2} Q_k\phi\left( \frac{t - \mu_k}{\sigma_k}\right)
\end{align}
with $\phi(x)$ the standard normal density. As a result
\begin{align}
    \frac{\partial Z}{\partial \mu_k} &= \int \frac{\partial \zeta}{\partial \mu_k} dt = -Q_k \\
    \frac{\partial Z}{\partial \sigma_k} &= \int \frac{\partial \zeta}{\partial \sigma_k} dt = 0
\end{align}
These results are intuitive: $Z$ increases as we move the changepoint to the left (for a $0 \rightarrow 1$ transition with $Q = 1$), and the width of the transition region is immaterial when integrated over all time. For the observations, we have
\begin{align}
    \frac{\partial \overline{M}}{\partial \mu_k} &= \int \rho(t) \frac{\partial \zeta}{\partial \mu_k} dt = -\frac{Q_k}{\sigma_k}\sum_i \phi\left( \frac{t_i - \mu_k}{\sigma_k}\right) \\
    \frac{\partial \overline{M}}{\partial \sigma_k} &= \int \rho(t) \frac{\partial \zeta}{\partial \sigma_k} dt = Q_k\sum_i \frac{t_i - \mu_k}{\sigma_k}\phi\left( \frac{t_i - \mu_k}{\sigma_k}\right)
\end{align}
Therefore, in the case that the prior on changepoints, $p(c)$ is flat, we have the gradients
\begin{align}
    \frac{\partial \mathcal{L}}{\partial \mu_k} &= -\frac{Q_k}{\sigma_k}\sum_i \phi\left( \frac{t_i - \mu_k}{\sigma_k}\right) \log (\lambda \nu)
    + \lambda (\nu - 1) Q_k \\
    \frac{\partial \mathcal{L}}{\partial \sigma_k} &=
    Q_k\sum_i \frac{t_i - \mu_k}{\sigma_k}\phi\left( \frac{t_i - \mu_k}{\sigma_k}\right) \log \nu + \frac{1}{\sigma_k}
\end{align}

\section{MAP approach}
As a first pass, we can also consider a maximum \emph{a posteriori} approach in which we only look for the (highest posterior probability) locations of changepoints. In this case, we simply replace $z(t)$ with either 0 or 1, giving
\begin{align}
    \mathcal{L} &= M \log \lambda + M_1 \log \nu - \lambda T [1 - f_1 + f_1 \nu] + \mathbb{E}_q[\log p(c)] + \frac{K}{2} \log (2\pi e\sigma^2_{\mathrm{min}})
\end{align}
with $M$ the total number of events $M_1$ number of events that happen in state 1, and $f_1 = T_1 / T$ the fraction of total time $T$ spent in state 1. Here, we have not entirely eliminated the uncertainty $\sigma$, but have replaced it with $\sigma_{\mathrm{min}}$, a minimum width that is perhaps smaller than the measurement time resolution, so that $\log \sigma_{\mathrm{min}}$ can be treated as a large negative constant. As a result, when attempting to maximize $\mathcal{L}$, there is a penalty for increasing $K$, in addition to whatever prior penalty is imposed by $p(c)$.

Alternately, we can rewrite this maximization objective as minimization objective equal to a sum over cost functions for each partition plus a penalty on large partition numbers:
\begin{align}
    \mathcal{L}' &= \mathcal{C}(\ell) + K \Delta \\
    \mathcal{C}(\ell) &=
    \begin{cases}
        -M_\ell \log \lambda + \lambda \ell - p(\ell|0) & z_\ell = 0 \\
        -M_\ell \log \lambda\nu + \lambda\nu \ell - p(\ell|1) & z_\ell = 1
    \end{cases}
\end{align}
where $\ell$ denotes the partition, $z_\ell$ the partition label, $M_\ell$ the number of events inside the partition, and $p(\ell|z_\ell)$ the prior over partition sizes. Furthermore, we have assumed a fixed penalty for each changepoint, $\Delta = -\frac{1}{2}\log 2\pi \sigma^2_\mathrm{min}$.

Unfortunately, this cost function does not (naively) allow for optimizations such as PELT (Killick et al., 2012), which require that adding a changepoint always decrease the cost, so that effective pruning becomes possible. In fact, there are two key differences:
\begin{itemize}
    \item Because we have only two possible states (the same would be true for any fixed, finite number), changepoints must enter in pairs to preserve boundary conditions. That is, when looking at a region with $z = 1$, the correct operation to attempt is inserting \emph{two} changepoints inside it, i.e., inserting a region of $z = 0$. Boundary conditions are thus more complicated, and search has to range over two endpoints, not one.

    \item It is usually safe to assume that the prior over state durations, $p(\ell|z)$, is unimodal, but it is certainly not monotonic in $\ell$, which adds additional complexity to the optimization problem.
\end{itemize}

\section{Linear time approach}
Here, we relax our formulation of the problem to allow for an approach that computes a segmentation in time complexity $\mathcal{O}(T)$. As we show below, our approach falls under the requirements of the pruned exact linear time (PELT) algorithm (Killick, Fearnhead, Eckley, JASA, 2012).

First, consider the same setup as above:
\begin{align}
    N(t) &\sim \mathrm{Pois}(r(t)) \\
    r(t) &= \lambda \nu^{z(t)}
\end{align}
We would again like to maximize the evidence lower bound. For the moment, we will not assume any form for $p(\ell|z)$, writing $\mathcal{P} = -\log p(\ell|z)$ as a penalty term for unlikely splittings of the data. As a result, we can then write the objective function as
\begin{equation}
    \mathbb{E}_q \left[\log p(N|z) \right] + \mathcal{H}[q(z)] - \mathcal{P}
\end{equation}
Now, however, we would like to choose a posterior approximation $q(z)$ consisting of the set of binary, piecewise-constant functions with fixed changepoints. That is, we will approximate the posterior over $z(t)$ as a sequence of Bernoulli posteriors, with the changepoints taken as \emph{variational parameters}. As a result, we do not need posteriors over the changepoint locations, but each segment will have a full posterior over $z$.

Given this set of assumptions, we can then write the objective function as a sum over segments:
\begin{equation}
    \mathcal{L} = \sum_k \left[
    \mathbb{E}[LL_k] + H(\pi_k)
    - \mathcal{P}_k
    \right]
\end{equation}
with
\begin{align}
    \mathbb{E}[LL] &= \sum_{l = 1}^\ell [N_l \log \lambda + \pi N_l \log \nu - \lambda (1 - \pi + \nu \pi) - \log N_l! ]\\
    &= \sum_l \log p(N_l|\lambda) + \pi [N\log \nu - \lambda (\nu - 1) \ell] \\
    &= \sum_l \log p(N_l|\lambda) + \pi \kappa \\
    H(\pi) &= -\pi \log \pi - (1 - \pi) \log (1 - \pi)
\end{align}
with $\kappa \equiv N\log \nu - \lambda (\nu - 1)\ell$, $N = \sum_l N_l$ and $H \ge 0$, the differential entropy of the Bernoulli distribution. This objective clearly has the form of a sum over ``maximum likelihoods" for each segment, as well as a changepoint ``penalty'' term. As shown in the PELT paper, the necessary condition for the pruning to work is a guarantee on the benefit of adding an additional changepoint:
\begin{equation}
    \label{pelt_condition}
    \mathcal{C}_1 + \mathcal{C}_2 + K \le \mathcal{C}_{1 \cup 2}
\end{equation}
for some $K \ge 0$ with $\mathcal{C} = -\mathcal{L} - \mathcal{P}$. With this guarantee, it then becomes possible to prune the potential changepoint locations in the recursive dynamic program, achieving linear running time.

We can easily derive the optimal value of $\pi$ in each segment:
\begin{align}
    \frac{\partial \mathcal{C}}{\partial \pi} &= -N\log \nu + \lambda (\nu - 1)\ell + \log \frac{\pi}{1-\pi} = 0 \\
    \Rightarrow \quad \pi &= \frac{1}{1 + e^{-\kappa}}
\end{align}
This then gives a maximal objective/minimal cost value for a segment defined by $N, \ell$ of
\begin{equation}
    \mathcal{C}_* = -\sum_l \log p(N_l|\lambda) -\kappa - \log (1 + e^{-\kappa})
\end{equation}
This leads us to

\subsection*{Theorem:} The cost function $\mathcal{C}_*$ satisfies (\ref{pelt_condition}) with $K = 0$.

\emph{Proof}: Consider splitting a section of data in two. We wish to show
\begin{equation}
    \mathcal{C}_*(N_1, \ell_1) + \mathcal{C}_*(N_2, \ell_2) \le \mathcal{C}_*(N, \ell)
\end{equation}
In this equation, we consider $\lambda$, $\nu$, $N$, $\ell$, $N_i$, and $\ell_i$ as given, with $\pi$ chosen in each segment to maximize $\mathcal{C}$. We begin by noting that our division of the data will result in a $\kappa_i$ with each new segment satisfying $\kappa_1 + \kappa_2 = \kappa$. As a result, we rewrite $\kappa_1 \equiv \alpha \kappa$, note that the ``base rate'' log likelihood terms are purely additive, and look for bounds of the form
\begin{equation}
    \alpha \kappa + \log(1 + e^{-\alpha \kappa}) +
    (1 - \alpha) \kappa + \log(1 + e^{-(1 - \alpha) \kappa})
    -K \ge
    \kappa + \log (1 + e^{-\kappa})
\end{equation}
which can be reduced:
\begin{align}
    \log(1 + e^{-\alpha \kappa}) +
    \log(1 + e^{-(1 - \alpha) \kappa})
    -K &\ge
    \log (1 + e^{-\kappa}) \\
    (1 + e^{-\alpha \kappa})
    (1 + e^{-(1 - \alpha) \kappa})
    e^{-K} &\ge
    (1 + e^{-\kappa}) \\
    \frac{1 + e^{-\kappa} + e^{-\alpha\kappa} + e^{-(1 - \alpha)\kappa}}{1 + e^{-\kappa}} &\ge e^K \\
    1 + \frac{e^{-\alpha\kappa} + e^{-(1 - \alpha)\kappa}}{1 + e^{-\kappa}} &\ge e^K
\end{align}
which is clearly satisfied if $K = 0$.

As a result, at each step of the PELT algorithm, the calculation
\begin{equation}
    F(\tau^*) = \min_{\tau \in R_{\tau^*}} [F(\tau) + \mathcal{C}_*(\tau + 1:\tau^*) + \mathcal{P}]
\end{equation}
is a single straightforward function evaluation at each $\tau$, which implies that the feasible set for the subsequent iteration is given by
\begin{equation}
    R_{\tau^* + 1} = \lbrace \tau^* \cup
    \lbrace
    \tau \in R_{\tau^*} \vert F(\tau) + \mathcal{C}_*(\tau + 1:\tau^*) <
    F(\tau^*)
    \rbrace \rbrace
\end{equation}

\subsection{Penalty term}
The total penalty for observing a sequence of changepoints in the model above is given by the negative log likelihood of observing the entire sequence:
\begin{equation}
    \mathcal{P}_\mathrm{tot} = -\sum_k \log p(\ell_k|z_k)
\end{equation}
However, we might wish to consider an alternative formulation, in which the prior is over the number of changepoints, not the length of each sequence. In this case, for $m$ changepoints, we have
\begin{equation}
    \mathcal{P}_\mathrm{tot} = -\log p(m)
\end{equation}
Now, if we assume a simple model in which the number of changepoints is exponentially distributed, we have
\begin{equation}
    \mathcal{P} = m\beta
\end{equation}
for some ``rate'' $\beta$. In this case, we arrive back at the setup in Killick et al., who consider a constant per-changepoint cost $\beta$.\footnote{Note that in this case, the number of changepoints is not assumed to increase in time unless $\beta \propto T^{-1}$. We might additionally consider the more complex setup of Killick et al.'s Section 3.2, which covers concave penalties, including exponential family forms like the Poisson.}

In addition, we may note the following interpretation of $\beta$ in the case that the cost $\mathcal{C}$ of a segment is equal to the negative log likelihood of the data in that segment:

Consider a case in which we are just indifferent between inserting a changepoint. In that case,
\begin{equation}
    \mathcal{C}(N_1, \ell_1) + \mathcal{C}(N_2, \ell_2) + \beta = \mathcal{C}(N, \ell)
\end{equation}
However, writing the cost as $\mathcal{C} = -\log \mathcal{L}$ gives
\begin{equation}
    \beta = \log \frac{\mathcal{L}(N_1, \ell_1)\mathcal{L}(N_2, \ell_2)}{\mathcal{L}(N, \ell)}
\end{equation}
That is, $\beta$ is the value of the log likelihood ratio of the two models at which we are indifferent to splitting. Thus, for example a value $\beta = 2$ requires that the data be twice as likely under the model with the changepoint as under the model without.

\end{document}